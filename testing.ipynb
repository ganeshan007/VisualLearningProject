{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "from predictor import ConvLayer, ReflectionPadConv, ResidualBlock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 16, 16])\n",
      "torch.Size([64, 3, 16, 16])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 49152 / 49152 (100.0%)\nGreatest absolute difference: 0.05875449627637863 at index (0, 2, 0, 0) (up to 1e-05 allowed)\nGreatest relative difference: 4.754302501678467 at index (0, 2, 0, 0) (up to 1e-05 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(output1\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(output2\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 10\u001b[0m torch\u001b[39m.\u001b[39;49mtesting\u001b[39m.\u001b[39;49massert_close(output1, output2, rtol\u001b[39m=\u001b[39;49m\u001b[39m1e-5\u001b[39;49m, atol\u001b[39m=\u001b[39;49m\u001b[39m1e-5\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/testing/_comparison.py:1511\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1489\u001b[0m error_metas \u001b[39m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1490\u001b[0m     actual,\n\u001b[1;32m   1491\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1506\u001b[0m     msg\u001b[39m=\u001b[39mmsg,\n\u001b[1;32m   1507\u001b[0m )\n\u001b[1;32m   1509\u001b[0m \u001b[39mif\u001b[39;00m error_metas:\n\u001b[1;32m   1510\u001b[0m     \u001b[39m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mraise\u001b[39;00m error_metas[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 49152 / 49152 (100.0%)\nGreatest absolute difference: 0.05875449627637863 at index (0, 2, 0, 0) (up to 1e-05 allowed)\nGreatest relative difference: 4.754302501678467 at index (0, 2, 0, 0) (up to 1e-05 allowed)"
     ]
    }
   ],
   "source": [
    "input = torch.randn((64,3,32,32))\n",
    "c1 = ConvLayer(3,3,5,2)\n",
    "c2 = ReflectionPadConv(3,3,5,2)\n",
    "c1 = c1.eval()\n",
    "c2 = c2.eval()\n",
    "output1 = c1(input)\n",
    "output2 = c2(input)\n",
    "print(output1.shape)\n",
    "print(output2.shape)\n",
    "torch.testing.assert_close(output1, output2, rtol=1e-5, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2608.5713, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(torch.abs(output1-output2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    reflection_pad = self.reflection_pad(x);  x = None\n",
      "    conv2d = self.conv2d(reflection_pad);  reflection_pad = None\n",
      "    return conv2d\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from torch.fx import symbolic_trace\n",
    "\n",
    "symbolic_traced = symbolic_trace(c1)\n",
    "\n",
    "print(symbolic_traced.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResidualBlock(\n",
      "  (in1): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  (conv1): Module(\n",
      "    (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (in2): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (conv2): Module(\n",
      "    (padding): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    in1 = self.in1(x)\n",
      "    relu = self.relu(in1);  in1 = None\n",
      "    conv1_padding = self.conv1.padding(relu);  relu = None\n",
      "    conv1_conv = self.conv1.conv(conv1_padding);  conv1_padding = None\n",
      "    in2 = self.in2(conv1_conv);  conv1_conv = None\n",
      "    relu_1 = self.relu(in2);  in2 = None\n",
      "    conv2_padding = self.conv2.padding(relu_1);  relu_1 = None\n",
      "    conv2_conv = self.conv2.conv(conv2_padding);  conv2_padding = None\n",
      "    add = conv2_conv + x;  conv2_conv = x = None\n",
      "    return add\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "from torch.fx import symbolic_trace\n",
    "res_block = ResidualBlock(3)\n",
    "print(symbolic_trace(res_block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.793722108310216 0.4393184535671582\n",
      "recall 0.8238810641627543 0.3919111111111111\n",
      "f1 0.8085204410725804 0.4142628958000564\n"
     ]
    }
   ],
   "source": [
    "tp = 4409\n",
    "fp = 5627\n",
    "fn = 6841\n",
    "tn = 26323\n",
    "precision_0 = tn / (tn+fn)\n",
    "recall_0 = tn / (tn+fp)\n",
    "precision_1 = tp / (tp+fp)\n",
    "recall_1 = tp / (tp+fn)\n",
    "f1_0 = 2*(recall_0*precision_0)/(recall_0+precision_0)\n",
    "f1_1 = 2*(recall_1*precision_1)/(recall_1+precision_1)\n",
    "\n",
    "print('precision',precision_0, precision_1)\n",
    "print('recall',recall_0, recall_1)\n",
    "print('f1',f1_0, f1_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1,2,3,4))\n",
    "z = torch.randn((2,2))\n",
    "z = z.view(*z.shape,1,1).expand(*z.shape,x.shape[2],x.shape[3])\n",
    "# z = z.view(z.size(0), z.size(1), 1, 1).expand(z.shape[0], z.shape[1], x.shape[0], x.shape[1])\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input_tensor):\n",
    "    # Get the dimensions of the input tensor\n",
    "    batch_size, num_features, height, width = input_tensor.size()\n",
    "\n",
    "    # Reshape the input tensor to a 2D matrix of shape (num_features, height * width)\n",
    "    features = input_tensor.view(batch_size * num_features, height * width)\n",
    "\n",
    "    # Calculate the Gram matrix by multiplying the reshaped features matrix with its transpose\n",
    "    gram = torch.matmul(features, features.t())\n",
    "\n",
    "    # Normalize the Gram matrix by dividing by the number of elements in each feature map\n",
    "    gram /= (batch_size * num_features * height * width)\n",
    "\n",
    "    return gram\n",
    "def gram2(input):\n",
    "    a, b, c, d = input.size()  # a=batch size(=1)\n",
    "    # b=number of feature maps\n",
    "    # (c,d)=dimensions of a f. map (N=c*d)\n",
    "\n",
    "    features = input.view(a * b, c * d)  # resise F_XL into \\hat F_XL\n",
    "\n",
    "    G = torch.mm(features, features.t())  # compute the gram product\n",
    "    # we 'normalize' the values of the gram matrix\n",
    "    # by dividing by the number of element in each feature maps.\n",
    "    return G.div(a * b * c * d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "features = torch.randn((1,2,3,4))\n",
    "f1 = gram_matrix(features)\n",
    "f2 = gram2(features)\n",
    "torch.testing.assert_close(f1, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.fx import symbolic_trace\n",
    "from allsome import *\n",
    "nl_layer = get_non_linearity(layer_type='lrelu')\n",
    "norm_layer = get_norm_layer(layer_type='batch')\n",
    "netE = E_ResNet(input_nc=3, output_nc=1, ndf=64, n_blocks=4, norm_layer=norm_layer,\n",
    "                        nl_layer=nl_layer, gpu_ids=[], vaeLike=False)\n",
    "sample_input = torch.randn(64, 3, 128, 128)\n",
    "output = netE(sample_input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
